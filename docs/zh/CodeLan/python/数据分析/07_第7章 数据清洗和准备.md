# 第7章 数据清洗和准备



## 7.1 处理缺失数据

* pandas使用浮点值NaN（Not a Number）表示缺失数据。哨兵值

### 滤除缺失数据

* ```python
  from numpy import nan as NA
  data = pd.Series([1, NA, 3.5, NA, 7])
  data.dropna()  ==  data[data.notnull()]
  ```

* DataFrame

  ```
  data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA],[NA, NA, NA], [NA, 6.5, 3.]])
  cleaned = data.dropna()
  In [22]: cleaned
  Out[22]: 
       0    1    2
  0  1.0  6.5  3.0
  ```

* 传入how='all'将只丢弃全为NA的那些行

  ```
  In [23]: data.dropna(how='all')
  Out[23]: 
       0    1    2
  0  1.0  6.5  3.0
  1  1.0  NaN  NaN
  3  NaN  6.5  3.0
  ```

  * name ‘NA’ is not defined
    * from numpy import nan as NA

* 只需传入axis=1即可： data.dropna(axis=1, how='all')

* 另一个滤除DataFrame行的问题涉及时间序列数据。假设你只想留下一部分观测数据，可以用thresh参数实现此目的：

  ```
  In [27]: df = pd.DataFrame(np.random.randn(7, 3))
  
  In [28]: df.iloc[:4, 1] = NA
  
  In [29]: df.iloc[:2, 2] = NA
  
  In [30]: df
  Out[30]: 
            0         1         2
  0 -0.204708       NaN       NaN
  1 -0.555730       NaN       NaN
  2  0.092908       NaN  0.769023
  3  1.246435       NaN -1.296221
  4  0.274992  0.228913  1.352917
  5  0.886429 -2.001637 -0.371843
  6  1.669025 -0.438570 -0.539741
  
  In [31]: df.dropna()
  Out[31]: 
            0         1         2
  4  0.274992  0.228913  1.352917
  5  0.886429 -2.001637 -0.371843
  6  1.669025 -0.438570 -0.539741
  
  In [32]: df.dropna(thresh=2)
  Out[32]: 
            0         1         2
  2  0.092908       NaN  0.769023
  3  1.246435       NaN -1.296221
  4  0.274992  0.228913  1.352917
  5  0.886429 -2.001637 -0.371843
  6  1.669025 -0.438570 -0.539741
  ```

### 填充缺失数据

* fillna
* 通过一个字典调用fillna，就可以实现对不同的列填充不同的值: df.fillna({1: 0.5, 2: 0})
* fillna默认会返回新对象，但也可以对现有对象进行就地修改: _ = df.fillna(0, inplace=True)
* 对reindexing有效的那些插值方法也可用于fillna：

## 7.2 数据转换

### 移除重复数据

```
data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],'k2': [1, 1, 2, 3, 3, 4, 4]})
```

* 是否重复：data.duplicated()
* 删除重复记录：data.drop_duplicates()
* 定部分列进行重复项判断： data.drop_duplicates(['k1'])
* 传入keep='last'则保留最后一个： data.drop_duplicates(['k1', 'k2'], keep='last')

### 利用函数或映射进行数据转换

```
data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',
   ....:                               'Pastrami', 'corned beef', 'Bacon',
   ....:                               'pastrami', 'honey ham', 'nova lox'],
   ....:                      'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})
   
meat_to_animal = {
  'bacon': 'pig',
  'pulled pork': 'pig',
  'pastrami': 'cow',
  'corned beef': 'cow',
  'honey ham': 'pig',
  'nova lox': 'salmon'
}
# 转换大小写
lowercased = data['food'].str.lower()
# 映射
data['animal'] = lowercased.map(meat_to_animal)
```

* 一个函数搞定：data['food'].map(lambda x: meat_to_animal[x.lower()])

### 替换值

* ```python
  data.replace(-999, np.nan)
  data.replace([-999, -1000], np.nan)
  ```

### 重命名轴索引

```
 data = pd.DataFrame(np.arange(12).reshape((3, 4)),
   ....:                     index=['Ohio', 'Colorado', 'New York'],
   ....:                     columns=['one', 'two', 'three', 'four'])
In [67]: transform = lambda x: x[:4].upper()

In [68]: data.index.map(transform)
Out[68]: Index(['OHIO', 'COLO', 'NEW '], dtype='object')  
data.index = data.index.map(transform)
```

* ```python
  data.rename(index=str.title, columns=str.upper)
  ```

### 离散化和面元划分

```
年龄： ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]
分段： bins = [18, 25, 35, 60, 100]
离散：cats = pd.cut(ages, bins)
```

* 统计：pd.value_counts(cats)

### 检测和过滤异常值

## 7.3 字符串操作

### 字符串对象方法

```
In [134]: val = 'a,b,  guido'
In [135]: val.split(',')
Out[135]: ['a', 'b', '  guido']
```

* 去除空格：pieces = [x.strip() for x in val.split(',')]

* 拆分+拼接

  ```
  In [138]: first, second, third = pieces
  
  In [139]: first + '::' + second + '::' + third
  Out[139]: 'a::b::guido'
  
  '::'.join(pieces) -> 'a::b::guido'
  ```

### 正则表达式

re模块的函数可以分为三个大类：模式匹配、替换以及拆分

* 一个或多个空白符的regex是\s+

  ```
  In [148]: import re
  In [149]: text = "foo    bar\t baz  \tqux"
  In [150]: re.split('\s+', text)
  Out[150]: ['foo', 'bar', 'baz', 'qux']
  ```

  ```
  In [151]: regex = re.compile('\s+')
  In [152]: regex.split(text)
  Out[152]: ['foo', 'bar', 'baz', 'qux']
  ```

* match和search跟findall功能类似。findall返回的是字符串中所有的匹配项，而search则只返回第一个匹配项。match更加严格，它只匹配字符串的首部。

  ```
  text = """Dave dave@google.com
  Steve steve@gmail.com
  Rob rob@gmail.com
  Ryan ryan@yahoo.com
  """
  pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}'
  
  # re.IGNORECASE makes the regex case-insensitive
  regex = re.compile(pattern, flags=re.IGNORECASE)
  
  In [155]: regex.findall(text)
  Out[155]: 
  ['dave@google.com',
   'steve@gmail.com',
   'rob@gmail.com',
   'ryan@yahoo.com']
  ```

* 将各个地址分成3个部分：用户名、域名以及域后缀（将待分段的模式的各部分用圆括号包起来）

  ```
  In [161]: pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]{2,4})'
  In [162]: regex = re.compile(pattern, flags=re.IGNORECASE)
  In [163]: m = regex.match('wesm@bright.net')
  
  In [164]: m.groups()
  Out[164]: ('wesm', 'bright', 'net')
  ```

  

### 